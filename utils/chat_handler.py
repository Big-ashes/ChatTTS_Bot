"""
èŠå¤©å¤„ç†é€»è¾‘
"""

import requests
import re
from typing import List, Tuple
from config import OLLAMA_URL, MODEL_NAME, GENERATION_CONFIG


class ChatHandler:
    def __init__(self):
        self.ollama_url = OLLAMA_URL
        self.model_name = MODEL_NAME
        self.generation_config = GENERATION_CONFIG

    def chat_with_ollama(self, message: str, history: List[Tuple[str, str]]) -> str:
        """ä¸Ollamaæ¨¡å‹å¯¹è¯"""
        try:
            # æ„å»ºä¸Šä¸‹æ–‡
            context = ""
            for user_msg, bot_msg in history:
                context += f"ç”¨æˆ·: {user_msg}\nåŠ©æ‰‹: {bot_msg}\n"

            full_prompt = f"{context}ç”¨æˆ·: {message}\nåŠ©æ‰‹: "

            # è°ƒç”¨Ollama API
            payload = {
                "model": self.model_name,
                "prompt": full_prompt,
                "stream": False,
                "options": self.generation_config
            }

            response = requests.post(
                self.ollama_url,
                json=payload,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                bot_response = result.get("response", "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆçš„å“åº”ã€‚")
                return bot_response.strip()
            else:
                return f"é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ (çŠ¶æ€ç : {response.status_code})"

        except requests.exceptions.RequestException as e:
            return f"è¿æ¥é”™è¯¯ï¼š{str(e)}"
        except Exception as e:
            return f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

    def parse_response(self, response: str) -> Tuple[str, str]:
        """è§£æå“åº”ï¼Œåˆ†ç¦»æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆå†…å®¹"""
        # æŸ¥æ‰¾ <think> æ ‡ç­¾
        think_pattern = r'<think>(.*?)</think>'
        think_match = re.search(think_pattern, response, re.DOTALL)

        if think_match:
            # æå–æ€è€ƒè¿‡ç¨‹
            think_content = think_match.group(1).strip()
            # æå–æ­£æ–‡å†…å®¹ï¼ˆç§»é™¤ <think> æ ‡ç­¾åçš„å‰©ä½™å†…å®¹ï¼‰
            main_content = re.sub(think_pattern, '', response, flags=re.DOTALL).strip()

            # æ ¼å¼åŒ–å®Œæ•´çš„æ˜¾ç¤ºå†…å®¹
            display_content = f"""**ğŸ¤” æ€è€ƒè¿‡ç¨‹ï¼š**

{think_content}

---

**ğŸ’¡ å›ç­”ï¼š**

{main_content}"""

            return display_content, main_content
        else:
            # æ²¡æœ‰æ€è€ƒæ ‡ç­¾ï¼Œç›´æ¥è¿”å›åŸå†…å®¹
            return response, response

    def process_message(self, message: str, history: List[Tuple[str, str]]) -> Tuple[str, str]:
        """å¤„ç†æ¶ˆæ¯å¹¶è¿”å›æ˜¾ç¤ºå†…å®¹å’ŒTTSå†…å®¹"""
        if not message.strip():
            return "", ""

        # è·å–æœºå™¨äººå“åº”
        raw_response = self.chat_with_ollama(message, history)

        # è§£æå“åº”ï¼Œåˆ†ç¦»æ€è€ƒè¿‡ç¨‹å’Œæ­£æ–‡
        display_content, tts_content = self.parse_response(raw_response)

        return display_content, tts_content